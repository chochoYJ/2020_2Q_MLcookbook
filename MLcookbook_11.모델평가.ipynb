{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 우리가 모델링을 하는 이유는 예측 성능이 높은 고품질의 모델을 만드는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 교차 검증 모델 만들기 : k-fold\n",
    "* 모델 훈련 -> fitting -> k-fold로 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits() \n",
    "features = digits.data # 특성행렬\n",
    "target = digits.target # 타깃벡터\n",
    "\n",
    "standardizer = StandardScaler() #표준화 객체 만들기\n",
    "logit = LogisticRegression() #로지스틱 회귀 객체 만들기\n",
    "\n",
    "# 표준화한 다음 로지스틱 회귀를 실행하는 파이프라인 제작\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# k-fold 교차검증 만들기\n",
    "kf = KFold(n_splits = 10, shuffle =True, random_state = 1)\n",
    "\n",
    "# k-fold 교차검증 수행\n",
    "cv_results = cross_val_score(pipeline, #파이프라인\n",
    "                            features, #특성행렬\n",
    "                            target, #타깃벡터\n",
    "                            cv = kf, #교차검증 기법 \n",
    "                            scoring = 'accuracy', #평가 지표\n",
    "                            n_jobs = -1) #모든 CPU 코어 사용 - 작업 속도 높임\n",
    "\n",
    "# 평균 계산\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전에 본 적 없는 데이터에서 얼마나 좋은 예측을 만들어낼 수 있는지 알 수 있기 위하여\n",
    "* 데이터의 일부를 테스트용으로 떼어둔다 = hold-out, validation(검증)\n",
    "\n",
    "#### 방법 1. Test_set, Training_set 으로 나누기\n",
    "* 검증에서 샘플은 training_set, test_set으로 나뉜다\n",
    "* training_set와 타겟벡터를 활용해서 최선의 예측을 만드는 방법을 모델 훈련으로 가르친다\n",
    "* test_set에서 모델의 성능을 평가한다\n",
    "* 한계 \n",
    "    * 모델 성능은 테스트 세트로 나뉜 일부 샘플에 의해 결정된다\n",
    "    * 전체 가용 데이터를 사용하여 모델을 훈련하고 테스트할 수 없다\n",
    "#### 방법 2. K-Fold cross validation (KFCV)\n",
    "* 데이터를 fold라고 부르는 K개의 부분으로 나눈다\n",
    "* K-1개를 합쳐 하나의 training_set으로 모델 훈련 후 나머지 1개를 test_set으로 사용한다\n",
    "* 이 과정을 K번 반복하여서 모델 성능을 평균하여 최종 성능을 산출함\n",
    "\n",
    "### KFold 결과값\n",
    "* cv_results : 10번의 test_set 성능 산출개별값 확인 가능\n",
    "\n",
    "### KFold 유의사항\n",
    "* 각 샘플이 다른 샘플과 독립적으로 생성되었다고 가정 ( Independent Identity Distributed )\n",
    "    * IID일때는 shuffle해준다 (why?) \n",
    "* 분류기를 평가할 경우 -> stratified k-fold\n",
    "    * KFold - >  StratifiedKFold\n",
    "    샘플 비중 일치시키기\n",
    "* 전처리 최종본을 test,train으로 나눠야 한다\n",
    "    * 편하게 해주는 도구 : pipeline\n",
    "\n",
    "### KFold의 주요한 매개변수들\n",
    "* cv = kf\n",
    "* scoring = 'accuracy'\n",
    "    모델성공의 측정 방법을 결정\n",
    "* n_jobs = -1\n",
    "    모든 CPU 코어 사용 -> 연산속도\n",
    "    \n",
    "### 기타\n",
    "* LOOCV : 폴드의 수가 k의 샘플의 개수와 같다 (LeaveOneOut)클래스 = KFold(n_splits=n) #n=샘플개수\n",
    "* ShuffleSplit : 반복횟수에 상관없이 훈련 폴드와 테스트 폴드 크기를 임의로 지정할 수 있음\n",
    "* StratifiedShuffleSplit : 계층별로 교차검증  \n",
    "교차검증 반복실행\n",
    "* RepeatedKFold\n",
    "* StratifiedRepeatedKFOld\n",
    "\n",
    "* 분할기를 만들고 -> cv 파라미터값을 다르게 설정해주면 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.1, random_state = 1)\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1617, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 기본 회귀 모델 만들기\n",
    "* DummyRegressor : 비교용으로 단순하게 만드는 것. 실제 문제 상황에서 사용할 거는 아님.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005676907086416438"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "features,target = boston.data, boston.target\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state = 1) # seed넘버\n",
    "\n",
    "dummy = DummyRegressor(strategy = 'mean') # 'constant'를 넣으면 모든 샘플에 대해 일정한 값으로 예측하는 더미 회귀 모델을 만들 수 있음\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.score(features_test, target_test) # R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789410172622865"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R squared\n",
    "* 결정계수\n",
    "* 설명력\n",
    "* 1에 가까울수록 타깃벡터의 분산을 잘 설명함\n",
    "\n",
    "#### DummyRegressor 파라미터\n",
    "* 'constant'\n",
    "* 'mean'\n",
    "* 'median'\n",
    "* 'quantile', quantile = 1.0 # max값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 기본 분류 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "features, target = iris.data, iris.target\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state =0) #seed넘버\n",
    "\n",
    "dummy = DummyClassifier(strategy = 'uniform', random_state = 1)\n",
    "\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeonjin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(features_train, target_train)\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 모델의 성능을 측정하는 일반적인 방법은, 랜덤한 추측보다 얼마나 더 나은지를 비교하는 것이다\n",
    "\n",
    "* strategy\n",
    "    * uniform\n",
    "    * stratified\n",
    "    * most_frequent : 훈련 세트 타깃에서 가장 많은 값으로 예측한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 34, 41])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
